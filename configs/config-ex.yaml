Trainer:
  epochs: Numero di epoche
  batch_size: int
  lr: learning rate
  l1: peso l1 regularization
  l2: peso l2 regularization
  optimizer:
    type: SGD / Adam
    momentum: ignored if adam
  Annealing:
    type: cosine/exponential/step/...
    altri parametri in base al tipo
  Early_stopping:
    tolerance: ...
    type:

Experiment:
  name: nome dell'esperimento
  save_path: percorso deve salvare
  save_model: true/false
  load_model: true/false

  Trainer: path al file trainer.yaml
  method: path al file method.yaml

Method:
  type: structured_pruning/pruning/l1pruning/...
  global_pruning: T/F
  iteraions: int
  prune_value: int se iteration non è presente altrimenti lista di interi o intero che verrà convertito in lista
  iterative_pruning: se il pruning satà iterativo
  finetuning_after_training: path a file trainer